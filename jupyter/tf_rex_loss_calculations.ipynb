{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script was to work out how best to implement REx in TensorFlow.\n",
    "\n",
    "Each mini-batch of data will contain an unknown number of records for each policy. Some policies may not be represented at all.\n",
    "\n",
    "It was important to correctly determine the loss for each policy, and the variance across the policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Records based on the Policy they belong to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be applied before the data is split among batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.],\n",
       "       [ 3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.],\n",
       "       [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of mock data\n",
    "data = np.reshape(np.arange(12, dtype=float), (4,3))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Â Assign every other record to policy 0, and the remainder to policy 1\n",
    "policies = np.array([0.,1.,0.,1.])[:, None]\n",
    "policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 for extracting records based on their policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [6., 7., 8.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[np.squeeze(np.argwhere(np.squeeze(policies)==0.)), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  4.,  5.],\n",
       "       [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[np.squeeze(np.argwhere(np.squeeze(policies)==1.)), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2 for extracting records based on their policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0302 09:45:42.794969 47371650098048 deprecation.py:323] From <ipython-input-7-1ae502cbc724>:1: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "WhereOp : Unhandled input dimensions: 0 [Op:Where] name: Where/",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-7-1ae502cbc724>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgather\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpolicies\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;36m0.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    322\u001B[0m               \u001B[0;34m'in a future version'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdate\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'after %s'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mdate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    323\u001B[0m               instructions)\n\u001B[0;32m--> 324\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    325\u001B[0m     return tf_decorator.make_decorator(\n\u001B[1;32m    326\u001B[0m         \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'deprecated'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36mwhere\u001B[0;34m(condition, x, y, name)\u001B[0m\n\u001B[1;32m   3266\u001B[0m       condition = ops.convert_to_tensor(\n\u001B[1;32m   3267\u001B[0m           condition, preferred_dtype=dtypes.bool, name=\"condition\")\n\u001B[0;32m-> 3268\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mgen_array_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3269\u001B[0m   \u001B[0;32melif\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0my\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3270\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001B[0m in \u001B[0;36mwhere\u001B[0;34m(condition, name)\u001B[0m\n\u001B[1;32m  11893\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  11894\u001B[0m         \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m> 11895\u001B[0;31m       \u001B[0m_six\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m  11896\u001B[0m   \u001B[0;31m# Add nodes to the TensorFlow graph.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  11897\u001B[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: WhereOp : Unhandled input dimensions: 0 [Op:Where] name: Where/"
     ]
    }
   ],
   "source": [
    "tf.gather(data, tf.squeeze(tf.where(tf.squeeze(policies)==0.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "WhereOp : Unhandled input dimensions: 0 [Op:Where] name: Where/",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-8-503e9b722b9f>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgather\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpolicies\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m==\u001B[0m\u001B[0;36m1.\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\u001B[0m in \u001B[0;36mnew_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    322\u001B[0m               \u001B[0;34m'in a future version'\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mdate\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m'after %s'\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mdate\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    323\u001B[0m               instructions)\n\u001B[0;32m--> 324\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    325\u001B[0m     return tf_decorator.make_decorator(\n\u001B[1;32m    326\u001B[0m         \u001B[0mfunc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_func\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'deprecated'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    178\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001B[0m in \u001B[0;36mwhere\u001B[0;34m(condition, x, y, name)\u001B[0m\n\u001B[1;32m   3266\u001B[0m       condition = ops.convert_to_tensor(\n\u001B[1;32m   3267\u001B[0m           condition, preferred_dtype=dtypes.bool, name=\"condition\")\n\u001B[0;32m-> 3268\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mgen_array_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3269\u001B[0m   \u001B[0;32melif\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0my\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3270\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mselect\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcondition\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001B[0m in \u001B[0;36mwhere\u001B[0;34m(condition, name)\u001B[0m\n\u001B[1;32m  11893\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  11894\u001B[0m         \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m> 11895\u001B[0;31m       \u001B[0m_six\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m  11896\u001B[0m   \u001B[0;31m# Add nodes to the TensorFlow graph.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m  11897\u001B[0m   _, _, _op = _op_def_lib._apply_op_helper(\n",
      "\u001B[0;32m/rds/project/rds-eWkDxBhxBrQ/dimorl/code/mopo/.env/lib/python3.6/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: WhereOp : Unhandled input dimensions: 0 [Op:Where] name: Where/"
     ]
    }
   ],
   "source": [
    "tf.gather(data, tf.squeeze(tf.where(tf.squeeze(policies)==1.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rex_beta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below simulates the MSEs for an ensemble of 4 models (`M`), each passed 3 observerations (`N`) with dimensionality of 2 (`D`). The matrix thus has dimensionality `MxNxD`, or `4x3x2` in this case.\n",
    "\n",
    "This is what would have been produced in the original code for the MSE - an error for each dimension in each record for each model.\n",
    "\n",
    "Remember that each model will recieve a different mini-batch of data, and so the policy of a record at a given index can/will vary across the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=7, shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 0.,  1.],\n",
       "        [ 2.,  3.],\n",
       "        [ 4.,  5.]],\n",
       "\n",
       "       [[ 6.,  7.],\n",
       "        [ 8.,  9.],\n",
       "        [10., 11.]],\n",
       "\n",
       "       [[12., 13.],\n",
       "        [14., 15.],\n",
       "        [16., 17.]],\n",
       "\n",
       "       [[18., 19.],\n",
       "        [20., 21.],\n",
       "        [22., 23.]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_arr = np.reshape(np.arange(24, dtype=float), (4,3,2))\n",
    "losses = tf.constant(losses_arr, dtype=float)\n",
    "losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning policies to each record fed to each model. There are 3 policies (`P`), and so while each model could recieve an observation from every policy, we've intentionally ensured this is not the case to capture cases where this arises in reality.\n",
    "\n",
    "The policies are stored in an `MxNx1` matrix - which would be extracted from the original data passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=9, shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[1.],\n",
       "        [1.],\n",
       "        [2.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [2.],\n",
       "        [2.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = tf.constant([\n",
    "    [\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [2.],\n",
    "    ],\n",
    "    [\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "    ],\n",
    "    [\n",
    "        [0.],\n",
    "        [2.],\n",
    "        [2.],\n",
    "    ],\n",
    "    [\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "    ]\n",
    "\n",
    "])\n",
    "policies#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mean across the number of dimensions - this is what the MOPO code does, rather than take the vector norm.\n",
    "\n",
    "In the below form, the observation losses could alternatively be the log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=12, shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[ 0.5],\n",
       "        [ 2.5],\n",
       "        [ 4.5]],\n",
       "\n",
       "       [[ 6.5],\n",
       "        [ 8.5],\n",
       "        [10.5]],\n",
       "\n",
       "       [[12.5],\n",
       "        [14.5],\n",
       "        [16.5]],\n",
       "\n",
       "       [[18.5],\n",
       "        [20.5],\n",
       "        [22.5]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_losses = tf.reduce_mean(losses, axis=-1, keepdims=True)\n",
    "obs_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the solution implemented in `mopo/models/bnn.py`. It was tested under a number of different scenarios to capture edge cases.\n",
    "\n",
    "Integers are used to identify policies - make sure that the data type is always correct by explicitly casting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14, shape=(4, 3, 1), dtype=int32, numpy=\n",
       "array([[[1],\n",
       "        [1],\n",
       "        [2]],\n",
       "\n",
       "       [[1],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [2],\n",
       "        [2]],\n",
       "\n",
       "       [[0],\n",
       "        [1],\n",
       "        [1]]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = tf.cast(policies, tf.int32)\n",
    "policies#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18, shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_pols = tf.unique(tf.reshape(policies, [-1])).y\n",
    "unique_pols#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the policy with the largest integer in the mini-batch. Note that there is no requirement that records be present for all policies.\n",
    "\n",
    "For instance, we may have records for policies [0, 1, 4] in the current mini-batch. The highest policy integer is therefore 4, and it does not matter that we do not have records for policy 3.\n",
    "\n",
    "Similarly, it may be that when looking at the entire dataset the highest policy integer is actually 5 - it does not matter if a mini-batch has no records for this policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=24, shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(unique_pols+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a one-hot encoded matrix which identifies the policy each record in the minibatch belongs to. This has dimension `MxNxP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=33, shape=(4, 3, 3), dtype=float32, numpy=\n",
       "array([[[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_one_hot = tf.squeeze(tf.one_hot(policies, tf.reduce_max(unique_pols+1), axis=-1), axis=-2)\n",
    "pol_one_hot#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the one-hot matrix to sum the losses for each policy - this has dimensions `MxP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=38, shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0. ,  3. ,  4.5],\n",
       "       [19. ,  6.5,  0. ],\n",
       "       [12.5,  0. , 31. ],\n",
       "       [18.5, 43. ,  0. ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_mean_sum = tf.squeeze(tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), obs_losses), axis=-1)\n",
    "pol_mean_sum#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the number of records present for each policy. Remember that we'd intentially designed the dataset so that each model received a mini-batch with no records for one policy.\n",
    "\n",
    "This has dimensions `MxP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=41, shape=(4, 3), dtype=float32, numpy=\n",
       "array([[0., 2., 1.],\n",
       "       [2., 1., 0.],\n",
       "       [1., 0., 2.],\n",
       "       [1., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_count = tf.reduce_sum(pol_one_hot, axis=-2)\n",
    "pol_count#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the mean loss for each policy. Use the `no_nan` method so that we do not get divide by zero errors (given that each model has no records for one policy).\n",
    "\n",
    "This again has dimensions `MxP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=43, shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0. ,  1.5,  4.5],\n",
       "       [ 9.5,  6.5,  0. ],\n",
       "       [12.5,  0. , 15.5],\n",
       "       [18.5, 21.5,  0. ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_losses = tf.math.divide_no_nan(pol_mean_sum, pol_count)\n",
    "policy_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the mean loss for each policy across the models - resulting in a matrix with dimension `P`.\n",
    "\n",
    "NOTE: This was calculated solely for information purposes, to track how the loss for each policy changed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=46, shape=(3,), dtype=float32, numpy=array([10.125,  7.375,  5.   ], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_policy_losses = tf.reduce_mean(policy_losses, axis=0)\n",
    "mean_policy_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum the policy losses for each model - resulting in a matrix with dimension `M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=49, shape=(4,), dtype=float32, numpy=array([ 6., 16., 28., 40.], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_total_losses = tf.reduce_sum(policy_losses, axis=-1)\n",
    "policy_total_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually determine what the variances should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.25, 2.25, 2.25, 2.25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(np.array((1.5,4.5))), np.var(np.array((9.5,6.5))), np.var(np.array((12.5,15.5))), np.var(np.array((18.5,21.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two methods of determining the variance for each model are shown below - both achieve the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=43, shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0. ,  1.5,  4.5],\n",
       "       [ 9.5,  6.5,  0. ],\n",
       "       [12.5,  0. , 15.5],\n",
       "       [18.5, 21.5,  0. ]], dtype=float32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=587, shape=(), dtype=float32, numpy=42.9375>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(tf.boolean_mask(policy_losses, pol_count>0.), axis=-1)#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_var(x):\n",
    "    batch_pol_losses, batch_pol_counts = x[0,:], x[1,:]\n",
    "    return tf.math.reduce_variance(tf.boolean_mask(batch_pol_losses, batch_pol_counts>0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=311, shape=(4,), dtype=float32, numpy=array([2.25, 2.25, 2.25, 2.25], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_var_losses = tf.map_fn(determine_var, tf.stack((policy_losses, pol_count), axis=-2))\n",
    "policy_var_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=313, shape=(4,), dtype=float32, numpy=array([ 8.25, 18.25, 30.25, 42.25], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss_var = policy_total_losses + policy_var_losses\n",
    "total_loss_var#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_abs_var(x):\n",
    "    batch_pol_losses, batch_pol_counts = x[0,:], x[1,:]\n",
    "    print('batch_pol_losses', batch_pol_losses)\n",
    "    mean = tf.math.reduce_mean(tf.boolean_mask(batch_pol_losses, batch_pol_counts>0.))\n",
    "    batch_pol_losses_var_abs = tf.math.abs(batch_pol_losses - mean)\n",
    "    return tf.math.reduce_mean(tf.boolean_mask(batch_pol_losses_var_abs, batch_pol_counts>0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=43, shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0. ,  1.5,  4.5],\n",
       "       [ 9.5,  6.5,  0. ],\n",
       "       [12.5,  0. , 15.5],\n",
       "       [18.5, 21.5,  0. ]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=712, shape=(), dtype=float32, numpy=11.25>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = tf.math.reduce_mean(tf.boolean_mask(policy_losses, pol_count>0.))\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=717, shape=(4, 3), dtype=float32, numpy=\n",
       "array([[11.25,  9.75,  6.75],\n",
       "       [ 1.75,  4.75, 11.25],\n",
       "       [ 1.25, 11.25,  4.25],\n",
       "       [ 7.25, 10.25, 11.25]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_losses_var_abs = tf.math.abs(policy_losses - mean)\n",
    "policy_losses_var_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pol_losses tf.Tensor([0.  1.5 4.5], shape=(3,), dtype=float32)\n",
      "batch_pol_losses tf.Tensor([9.5 6.5 0. ], shape=(3,), dtype=float32)\n",
      "batch_pol_losses tf.Tensor([12.5  0.  15.5], shape=(3,), dtype=float32)\n",
      "batch_pol_losses tf.Tensor([18.5 21.5  0. ], shape=(3,), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1405, shape=(4,), dtype=float32, numpy=array([1.5, 1.5, 1.5, 1.5], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_var_losses = tf.map_fn(determine_abs_var, tf.stack((policy_losses, pol_count), axis=-2))\n",
    "policy_var_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a complete method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       " array([[[ 0.,  1.],\n",
       "         [ 2.,  3.],\n",
       "         [ 4.,  5.]],\n",
       " \n",
       "        [[ 6.,  7.],\n",
       "         [ 8.,  9.],\n",
       "         [10., 11.]],\n",
       " \n",
       "        [[12., 13.],\n",
       "         [14., 15.],\n",
       "         [16., 17.]],\n",
       " \n",
       "        [[18., 19.],\n",
       "         [20., 21.],\n",
       "         [22., 23.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       " array([[[ 0.,  1.],\n",
       "         [ 2.,  3.],\n",
       "         [ 4.,  5.]],\n",
       " \n",
       "        [[ 6.,  7.],\n",
       "         [ 8.,  9.],\n",
       "         [10., 11.]],\n",
       " \n",
       "        [[12., 13.],\n",
       "         [14., 15.],\n",
       "         [16., 17.]],\n",
       " \n",
       "        [[18., 19.],\n",
       "         [20., 21.],\n",
       "         [22., 23.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_arr = np.reshape(np.arange(24, dtype=float), (4,3,2))\n",
    "mean = tf.constant(losses_arr, dtype=float)\n",
    "log_var = tf.identity(mean)\n",
    "mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[1.],\n",
       "        [1.],\n",
       "        [2.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [2.],\n",
       "        [2.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = tf.constant([\n",
    "    [\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [2.],\n",
    "    ],\n",
    "    [\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "    ],\n",
    "    [\n",
    "        [0.],\n",
    "        [2.],\n",
    "        [2.],\n",
    "    ],\n",
    "    [\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "    ]\n",
    "\n",
    "])\n",
    "policies#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=int32, numpy=\n",
       "array([[[1],\n",
       "        [1],\n",
       "        [2]],\n",
       "\n",
       "       [[1],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [2],\n",
       "        [2]],\n",
       "\n",
       "       [[0],\n",
       "        [1],\n",
       "        [1]]], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = tf.cast(policies, tf.int32)\n",
    "policies#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_pols = tf.unique(tf.reshape(policies, [-1])).y\n",
    "unique_pols#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 3), dtype=float32, numpy=\n",
       "array([[[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_one_hot = tf.squeeze(tf.one_hot(policies, tf.reduce_max(unique_pols+1), axis=-1), axis=-2)\n",
    "pol_one_hot#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[0., 2., 1.],\n",
       "       [2., 1., 0.],\n",
       "       [1., 0., 2.],\n",
       "       [1., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_count = tf.reduce_sum(pol_one_hot, axis=-2)\n",
    "pol_count#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple IRM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4), dtype=float64, numpy=array([[0., 1., 2., 3.]])>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 4) dtype=float64, numpy=array([[1., 1., 1., 1.]])>,\n",
       " <tf.Tensor: shape=(1, 4), dtype=float64, numpy=array([[0., 1., 2., 3.]])>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input =  tf.constant(np.reshape(np.arange(4, dtype=float), (1,4)))\n",
    "# test_w = tf.Variable(np.ones((1)), trainable=True)\n",
    "test_w = tf.Variable(np.ones_like(test_input), trainable=True)\n",
    "test_input, test_w, test_input*test_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float64, numpy=array([[ 0.,  2.,  8., 18.]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    result = (test_input*test_w)**2\n",
    "tape.gradient(result, test_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example - Same Form as Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dummy_w = tf.Variable(np.ones_like(mean), trainable=True, dtype=float)\n",
    "log_var_dummy_w = tf.Variable(np.ones_like(log_var), trainable=True, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[   0.,    2.],\n",
       "        [   8.,   18.],\n",
       "        [  32.,   50.]],\n",
       "\n",
       "       [[  72.,   98.],\n",
       "        [ 128.,  162.],\n",
       "        [ 200.,  242.]],\n",
       "\n",
       "       [[ 288.,  338.],\n",
       "        [ 392.,  450.],\n",
       "        [ 512.,  578.]],\n",
       "\n",
       "       [[ 648.,  722.],\n",
       "        [ 800.,  882.],\n",
       "        [ 968., 1058.]]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape_mean:\n",
    "    with tf.GradientTape(persistent=True) as tape_log_var:\n",
    "        mean_w = mean * mean_dummy_w\n",
    "        obs_losses = tf.reduce_sum(mean_w**2, axis=-1, keepdims=True)\n",
    "\n",
    "mean_dummy_grads = tape_mean.gradient(obs_losses, mean_dummy_w)\n",
    "log_var_dummy_grads =  tape_log_var.gradient(obs_losses, log_var_dummy_w)\n",
    "mean_dummy_grads#, log_var_dummy_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[1.000e+00],\n",
       "        [1.300e+01],\n",
       "        [4.100e+01]],\n",
       "\n",
       "       [[8.500e+01],\n",
       "        [1.450e+02],\n",
       "        [2.210e+02]],\n",
       "\n",
       "       [[3.130e+02],\n",
       "        [4.210e+02],\n",
       "        [5.450e+02]],\n",
       "\n",
       "       [[6.850e+02],\n",
       "        [8.410e+02],\n",
       "        [1.013e+03]]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[   0.,    0.],\n",
       "        [   8.,   20.],\n",
       "        [  32.,   50.]],\n",
       "\n",
       "       [[ 328.,  404.],\n",
       "        [  72.,   98.],\n",
       "        [   0.,    0.]],\n",
       "\n",
       "       [[ 288.,  338.],\n",
       "        [   0.,    0.],\n",
       "        [ 904., 1028.]],\n",
       "\n",
       "       [[ 648.,  722.],\n",
       "        [1768., 1940.],\n",
       "        [   0.,    0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_mean_dummy_grad_sum = tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), mean_dummy_grads)\n",
    "pol_mean_dummy_grad_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
       "array([3.988000e+03, 2.855880e+05, 2.071188e+06, 7.830612e+06],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reduce_sum((pol_mean_dummy_grad_sum**2), axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape_mean:\n",
    "    with tf.GradientTape() as tape_log_var:\n",
    "        mean_w = mean * mean_dummy_w\n",
    "        log_var_w = log_var * log_var_dummy_w\n",
    "        inv_var_w = tf.exp(-log_var_w)\n",
    "        obs_mse_losses = tf.reduce_mean(tf.square(mean_w - (mean+0.1)) * inv_var_w, axis=-1, keepdims=True)\n",
    "        obs_var_losses = tf.reduce_mean(log_var_w, axis=-1, keepdims=True)\n",
    "        obs_losses = obs_mse_losses + obs_var_losses\n",
    "        pol_mean_sum = tf.squeeze(tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), obs_losses), axis=-1)\n",
    "        policy_losses = tf.math.divide_no_nan(pol_mean_sum, pol_count)\n",
    "\n",
    "mean_dummy_grads = tape_mean.gradient(policy_losses, mean_dummy_w)\n",
    "log_var_dummy_grads = tape_log_var.gradient(policy_losses, log_var_dummy_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[ 0.5068394],\n",
       "        [ 2.5009255],\n",
       "        [ 4.5001254]],\n",
       "\n",
       "       [[ 6.500017 ],\n",
       "        [ 8.500002 ],\n",
       "        [10.5      ]],\n",
       "\n",
       "       [[12.5      ],\n",
       "        [14.5      ],\n",
       "        [16.5      ]],\n",
       "\n",
       "       [[18.5      ],\n",
       "        [20.5      ],\n",
       "        [22.5      ]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[-0.0000000e+00, -1.8393977e-02],\n",
       "        [-1.3533515e-02, -7.4680536e-03],\n",
       "        [-7.3262486e-03, -3.3689705e-03]],\n",
       "\n",
       "       [[-1.4872500e-03, -6.3831673e-04],\n",
       "        [-1.3418557e-04, -5.5534623e-05],\n",
       "        [-2.2700051e-05, -9.1859702e-06]],\n",
       "\n",
       "       [[-7.3730830e-06, -2.9384394e-06],\n",
       "        [-5.8207235e-07, -2.2942763e-07],\n",
       "        [-9.0028486e-08, -3.5189608e-08]],\n",
       "\n",
       "       [[-2.7414071e-08, -1.0645354e-08],\n",
       "        [-2.0611615e-09, -7.9617191e-10],\n",
       "        [-3.0684266e-10, -1.1801207e-10]]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dummy_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
       "array([-5.0090764e-02, -2.3471732e-03, -1.1248240e-05, -4.1341615e-08],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reduce_sum(tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), mean_dummy_grads), axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 5.9974957, 15.999882 , 28.       , 40.       ], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reduce_sum(tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), log_var_dummy_grads), axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0.5068394,  2.5009255,  4.5001254],\n",
       "       [ 6.500017 ,  8.500002 , 10.5      ],\n",
       "       [12.5      , 14.5      , 16.5      ],\n",
       "       [18.5      , 20.5      , 22.5      ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(obs_losses)#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.map_fn(lambda x: tf.gradients(x, mean_dummy_w)[0], tf.squeeze(obs_losses, axis=-1)).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.gradients(obs_losses, mean_dummy_w)[0].eval(session=sess), tf.gradients(obs_losses, log_var_dummy_w)[0].eval(session=sess)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0762be2d7dad499f78b4ccc05029bbe082222b827c654f817432570f6c80b9f2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
