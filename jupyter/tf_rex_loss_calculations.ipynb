{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script was to work out how best to implement REx in TensorFlow.\n",
    "\n",
    "Each mini-batch of data will contain an unknown number of records for each policy. Some policies may not be represented at all.\n",
    "\n",
    "It was important to correctly determine the loss for each policy, and the variance across the policies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 11:37:39.722894: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ajc348/.mujoco/mujoco210/bin:/home/ajc348/.mujoco/mujoco210/bin:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.7:/usr/local/Cluster-Apps/intel/2017.4/debugger_2017/iga/lib:/usr/local/Cluster-Apps/intel/2017.4/debugger_2017/libipt/intel64/lib:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/usr/local/software/global/lib:/usr/local/Cluster-Apps/vgl/2.5.1/64/lib:/usr/local/software/slurm/current/lib\n",
      "2022-10-13 11:37:39.722939: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-13 11:38:54.311822: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/ajc348/.mujoco/mujoco210/bin:/home/ajc348/.mujoco/mujoco210/bin:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/daal/lib/intel64_lin:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/daal/../tbb/lib/intel64_lin/gcc4.4:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/ipp/lib/intel64:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64/gcc4.7:/usr/local/Cluster-Apps/intel/2017.4/debugger_2017/iga/lib:/usr/local/Cluster-Apps/intel/2017.4/debugger_2017/libipt/intel64/lib:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/mpi/intel64/lib:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/tbb/lib/intel64_lin/gcc4.7:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/mkl/lib/intel64_lin:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64:/usr/local/Cluster-Apps/intel/2017.4/compilers_and_libraries_2017.4.196/linux/compiler/lib/intel64_lin:/usr/local/software/global/lib:/usr/local/Cluster-Apps/vgl/2.5.1/64/lib:/usr/local/software/slurm/current/lib\n",
      "2022-10-13 11:38:54.312446: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-13 11:38:54.312497: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (login-e-15): /proc/driver/nvidia/version does not exist\n",
      "2022-10-13 11:38:54.331540: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.compat.v1.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Records based on the Policy they belong to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would be applied before the data is split among batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.],\n",
       "       [ 3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.],\n",
       "       [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation of mock data\n",
    "data = np.reshape(np.arange(12, dtype=float), (4,3))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Â Assign every other record to policy 0, and the remainder to policy 1\n",
    "policies = np.array([0.,1.,0.,1.])[:, None]\n",
    "policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 for extracting records based on their policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2.],\n",
       "       [6., 7., 8.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[np.squeeze(np.argwhere(np.squeeze(policies)==0.)), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.,  4.,  5.],\n",
       "       [ 9., 10., 11.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[np.squeeze(np.argwhere(np.squeeze(policies)==1.)), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2 for extracting records based on their policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
       "array([[0., 1., 2.],\n",
       "       [6., 7., 8.]])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(data, tf.squeeze(tf.where(tf.squeeze(policies)==0.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float64, numpy=\n",
       "array([[ 3.,  4.,  5.],\n",
       "       [ 9., 10., 11.]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.gather(data, tf.squeeze(tf.where(tf.squeeze(policies)==1.)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rex_beta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below simulates the MSEs for an ensemble of 4 models (`M`), each passed 3 observerations (`N`) with dimensionality of 2 (`D`). The matrix thus has dimensionality `MxNxD`, or `4x3x2` in this case.\n",
    "\n",
    "This is what would have been produced in the original code for the MSE - an error for each dimension in each record for each model.\n",
    "\n",
    "Remember that each model will recieve a different mini-batch of data, and so the policy of a record at a given index can/will vary across the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[ 0.,  1.],\n",
       "        [ 2.,  3.],\n",
       "        [ 4.,  5.]],\n",
       "\n",
       "       [[ 6.,  7.],\n",
       "        [ 8.,  9.],\n",
       "        [10., 11.]],\n",
       "\n",
       "       [[12., 13.],\n",
       "        [14., 15.],\n",
       "        [16., 17.]],\n",
       "\n",
       "       [[18., 19.],\n",
       "        [20., 21.],\n",
       "        [22., 23.]]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses_arr = np.reshape(np.arange(24, dtype=float), (4,3,2))\n",
    "losses = tf.constant(losses_arr, dtype=float)\n",
    "losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assigning policies to each record fed to each model. There are 3 policies (`P`), and so while each model could recieve an observation from every policy, we've intentionally ensured this is not the case to capture cases where this arises in reality.\n",
    "\n",
    "The policies are stored in an `MxNx1` matrix - which would be extracted from the original data passed to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[1.],\n",
       "        [1.],\n",
       "        [2.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [2.],\n",
       "        [2.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = tf.constant([\n",
    "    [\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [2.],\n",
    "    ],\n",
    "    [\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "    ],\n",
    "    [\n",
    "        [0.],\n",
    "        [2.],\n",
    "        [2.],\n",
    "    ],\n",
    "    [\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "    ]\n",
    "\n",
    "])\n",
    "policies#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the mean across the number of dimensions - this is what the MOPO code does, rather than take the vector norm.\n",
    "\n",
    "In the below form, the observation losses could alternatively be the log-likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[ 0.5],\n",
       "        [ 2.5],\n",
       "        [ 4.5]],\n",
       "\n",
       "       [[ 6.5],\n",
       "        [ 8.5],\n",
       "        [10.5]],\n",
       "\n",
       "       [[12.5],\n",
       "        [14.5],\n",
       "        [16.5]],\n",
       "\n",
       "       [[18.5],\n",
       "        [20.5],\n",
       "        [22.5]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_losses = tf.reduce_mean(losses, axis=-1, keepdims=True)\n",
    "obs_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the solution implemented in `mopo/models/bnn.py`. It was tested under a number of different scenarios to capture edge cases.\n",
    "\n",
    "Integers are used to identify policies - make sure that the data type is always correct by explicitly casting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=int32, numpy=\n",
       "array([[[1],\n",
       "        [1],\n",
       "        [2]],\n",
       "\n",
       "       [[1],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [2],\n",
       "        [2]],\n",
       "\n",
       "       [[0],\n",
       "        [1],\n",
       "        [1]]], dtype=int32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = tf.cast(policies, tf.int32)\n",
    "policies#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_pols = tf.unique(tf.reshape(policies, [-1])).y\n",
    "unique_pols#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the policy with the largest integer in the mini-batch. Note that there is no requirement that records be present for all policies.\n",
    "\n",
    "For instance, we may have records for policies [0, 1, 4] in the current mini-batch. The highest policy integer is therefore 4, and it does not matter that we do not have records for policy 3.\n",
    "\n",
    "Similarly, it may be that when looking at the entire dataset the highest policy integer is actually 5 - it does not matter if a mini-batch has no records for this policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_max(unique_pols+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a one-hot encoded matrix which identifies the policy each record in the minibatch belongs to. This has dimension `MxNxP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 3), dtype=float32, numpy=\n",
       "array([[[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_one_hot = tf.squeeze(tf.one_hot(policies, tf.reduce_max(unique_pols+1), axis=-1), axis=-2)\n",
    "pol_one_hot#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the one-hot matrix to sum the losses for each policy - this has dimensions `MxP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0. ,  3. ,  4.5],\n",
       "       [19. ,  6.5,  0. ],\n",
       "       [12.5,  0. , 31. ],\n",
       "       [18.5, 43. ,  0. ]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_mean_sum = tf.squeeze(tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), obs_losses), axis=-1)\n",
    "pol_mean_sum#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the number of records present for each policy. Remember that we'd intentially designed the dataset so that each model received a mini-batch with no records for one policy.\n",
    "\n",
    "This has dimensions `MxP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[0., 2., 1.],\n",
       "       [2., 1., 0.],\n",
       "       [1., 0., 2.],\n",
       "       [1., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_count = tf.reduce_sum(pol_one_hot, axis=-2)\n",
    "pol_count#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the mean loss for each policy. Use the `no_nan` method so that we do not get divide by zero errors (given that each model has no records for one policy).\n",
    "\n",
    "This again has dimensions `MxP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0. ,  1.5,  4.5],\n",
       "       [ 9.5,  6.5,  0. ],\n",
       "       [12.5,  0. , 15.5],\n",
       "       [18.5, 21.5,  0. ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_losses = tf.math.divide_no_nan(pol_mean_sum, pol_count)\n",
    "policy_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the mean loss for each policy across the models - resulting in a matrix with dimension `P`.\n",
    "\n",
    "NOTE: This was calculated solely for information purposes, to track how the loss for each policy changed during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([10.125,  7.375,  5.   ], dtype=float32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_policy_losses = tf.reduce_mean(policy_losses, axis=0)\n",
    "mean_policy_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum the policy losses for each model - resulting in a matrix with dimension `M`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 6., 16., 28., 40.], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_total_losses = tf.reduce_sum(policy_losses, axis=-1)\n",
    "policy_total_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually determine what the variances should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.25, 2.25, 2.25, 2.25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(np.array((1.5,4.5))), np.var(np.array((9.5,6.5))), np.var(np.array((12.5,15.5))), np.var(np.array((18.5,21.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two methods of determining the variance for each model are shown below - both achieve the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([2.25, 2.25, 2.25, 2.25], dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_variance(tf.ragged.boolean_mask(policy_losses, pol_count>0.), axis=-1)#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_var(x):\n",
    "    batch_pol_losses, batch_pol_counts = x[0,:], x[1,:]\n",
    "    return tf.math.reduce_variance(tf.boolean_mask(batch_pol_losses, batch_pol_counts>0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([2.25, 2.25, 2.25, 2.25], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_var_losses = tf.map_fn(determine_var, tf.stack((policy_losses, pol_count), axis=-2))\n",
    "policy_var_losses#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 8.25, 18.25, 30.25, 42.25], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss_var = policy_total_losses + policy_var_losses\n",
    "total_loss_var#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not a complete method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       " array([[[ 0.,  1.],\n",
       "         [ 2.,  3.],\n",
       "         [ 4.,  5.]],\n",
       " \n",
       "        [[ 6.,  7.],\n",
       "         [ 8.,  9.],\n",
       "         [10., 11.]],\n",
       " \n",
       "        [[12., 13.],\n",
       "         [14., 15.],\n",
       "         [16., 17.]],\n",
       " \n",
       "        [[18., 19.],\n",
       "         [20., 21.],\n",
       "         [22., 23.]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       " array([[[ 0.,  1.],\n",
       "         [ 2.,  3.],\n",
       "         [ 4.,  5.]],\n",
       " \n",
       "        [[ 6.,  7.],\n",
       "         [ 8.,  9.],\n",
       "         [10., 11.]],\n",
       " \n",
       "        [[12., 13.],\n",
       "         [14., 15.],\n",
       "         [16., 17.]],\n",
       " \n",
       "        [[18., 19.],\n",
       "         [20., 21.],\n",
       "         [22., 23.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_arr = np.reshape(np.arange(24, dtype=float), (4,3,2))\n",
    "mean = tf.constant(losses_arr, dtype=float)\n",
    "log_var = tf.identity(mean)\n",
    "mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[1.],\n",
       "        [1.],\n",
       "        [2.]],\n",
       "\n",
       "       [[1.],\n",
       "        [0.],\n",
       "        [0.]],\n",
       "\n",
       "       [[0.],\n",
       "        [2.],\n",
       "        [2.]],\n",
       "\n",
       "       [[0.],\n",
       "        [1.],\n",
       "        [1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = tf.constant([\n",
    "    [\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [2.],\n",
    "    ],\n",
    "    [\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [0.],\n",
    "    ],\n",
    "    [\n",
    "        [0.],\n",
    "        [2.],\n",
    "        [2.],\n",
    "    ],\n",
    "    [\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "    ]\n",
    "\n",
    "])\n",
    "policies#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=int32, numpy=\n",
       "array([[[1],\n",
       "        [1],\n",
       "        [2]],\n",
       "\n",
       "       [[1],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [2],\n",
       "        [2]],\n",
       "\n",
       "       [[0],\n",
       "        [1],\n",
       "        [1]]], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policies = tf.cast(policies, tf.int32)\n",
    "policies#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 0], dtype=int32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_pols = tf.unique(tf.reshape(policies, [-1])).y\n",
    "unique_pols#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 3), dtype=float32, numpy=\n",
       "array([[[0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.]],\n",
       "\n",
       "       [[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_one_hot = tf.squeeze(tf.one_hot(policies, tf.reduce_max(unique_pols+1), axis=-1), axis=-2)\n",
    "pol_one_hot#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[0., 2., 1.],\n",
       "       [2., 1., 0.],\n",
       "       [1., 0., 2.],\n",
       "       [1., 2., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_count = tf.reduce_sum(pol_one_hot, axis=-2)\n",
    "pol_count#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple IRM Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4), dtype=float64, numpy=array([[0., 1., 2., 3.]])>,\n",
       " <tf.Variable 'Variable:0' shape=(1, 4) dtype=float64, numpy=array([[1., 1., 1., 1.]])>,\n",
       " <tf.Tensor: shape=(1, 4), dtype=float64, numpy=array([[0., 1., 2., 3.]])>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_input =  tf.constant(np.reshape(np.arange(4, dtype=float), (1,4)))\n",
    "# test_w = tf.Variable(np.ones((1)), trainable=True)\n",
    "test_w = tf.Variable(np.ones_like(test_input), trainable=True)\n",
    "test_input, test_w, test_input*test_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=float64, numpy=array([[ 0.,  2.,  8., 18.]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    result = (test_input*test_w)**2\n",
    "tape.gradient(result, test_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Example - Same Form as Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dummy_w = tf.Variable(np.ones_like(mean), trainable=True, dtype=float)\n",
    "log_var_dummy_w = tf.Variable(np.ones_like(log_var), trainable=True, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[   0.,    2.],\n",
       "        [   8.,   18.],\n",
       "        [  32.,   50.]],\n",
       "\n",
       "       [[  72.,   98.],\n",
       "        [ 128.,  162.],\n",
       "        [ 200.,  242.]],\n",
       "\n",
       "       [[ 288.,  338.],\n",
       "        [ 392.,  450.],\n",
       "        [ 512.,  578.]],\n",
       "\n",
       "       [[ 648.,  722.],\n",
       "        [ 800.,  882.],\n",
       "        [ 968., 1058.]]], dtype=float32)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape(persistent=True) as tape_mean:\n",
    "    with tf.GradientTape(persistent=True) as tape_log_var:\n",
    "        mean_w = mean * mean_dummy_w\n",
    "        obs_losses = tf.reduce_sum(mean_w**2, axis=-1, keepdims=True)\n",
    "\n",
    "mean_dummy_grads = tape_mean.gradient(obs_losses, mean_dummy_w)\n",
    "log_var_dummy_grads =  tape_log_var.gradient(obs_losses, log_var_dummy_w)\n",
    "mean_dummy_grads#, log_var_dummy_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[1.000e+00],\n",
       "        [1.300e+01],\n",
       "        [4.100e+01]],\n",
       "\n",
       "       [[8.500e+01],\n",
       "        [1.450e+02],\n",
       "        [2.210e+02]],\n",
       "\n",
       "       [[3.130e+02],\n",
       "        [4.210e+02],\n",
       "        [5.450e+02]],\n",
       "\n",
       "       [[6.850e+02],\n",
       "        [8.410e+02],\n",
       "        [1.013e+03]]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[   0.,    0.],\n",
       "        [   8.,   20.],\n",
       "        [  32.,   50.]],\n",
       "\n",
       "       [[ 328.,  404.],\n",
       "        [  72.,   98.],\n",
       "        [   0.,    0.]],\n",
       "\n",
       "       [[ 288.,  338.],\n",
       "        [   0.,    0.],\n",
       "        [ 904., 1028.]],\n",
       "\n",
       "       [[ 648.,  722.],\n",
       "        [1768., 1940.],\n",
       "        [   0.,    0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_mean_dummy_grad_sum = tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), mean_dummy_grads)\n",
    "pol_mean_dummy_grad_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
       "array([3.988000e+03, 2.855880e+05, 2.071188e+06, 7.830612e+06],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reduce_sum((pol_mean_dummy_grad_sum**2), axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape_mean:\n",
    "    with tf.GradientTape() as tape_log_var:\n",
    "        mean_w = mean * mean_dummy_w\n",
    "        log_var_w = log_var * log_var_dummy_w\n",
    "        inv_var_w = tf.exp(-log_var_w)\n",
    "        obs_mse_losses = tf.reduce_mean(tf.square(mean_w - (mean+0.1)) * inv_var_w, axis=-1, keepdims=True)\n",
    "        obs_var_losses = tf.reduce_mean(log_var_w, axis=-1, keepdims=True)\n",
    "        obs_losses = obs_mse_losses + obs_var_losses\n",
    "        pol_mean_sum = tf.squeeze(tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), obs_losses), axis=-1)\n",
    "        policy_losses = tf.math.divide_no_nan(pol_mean_sum, pol_count)\n",
    "\n",
    "mean_dummy_grads = tape_mean.gradient(policy_losses, mean_dummy_w)\n",
    "log_var_dummy_grads = tape_log_var.gradient(policy_losses, log_var_dummy_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 1), dtype=float32, numpy=\n",
       "array([[[ 0.5068394],\n",
       "        [ 2.5009255],\n",
       "        [ 4.5001254]],\n",
       "\n",
       "       [[ 6.500017 ],\n",
       "        [ 8.500002 ],\n",
       "        [10.5      ]],\n",
       "\n",
       "       [[12.5      ],\n",
       "        [14.5      ],\n",
       "        [16.5      ]],\n",
       "\n",
       "       [[18.5      ],\n",
       "        [20.5      ],\n",
       "        [22.5      ]]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3, 2), dtype=float32, numpy=\n",
       "array([[[-0.0000000e+00, -1.8393977e-02],\n",
       "        [-1.3533515e-02, -7.4680536e-03],\n",
       "        [-7.3262486e-03, -3.3689705e-03]],\n",
       "\n",
       "       [[-1.4872500e-03, -6.3831673e-04],\n",
       "        [-1.3418557e-04, -5.5534623e-05],\n",
       "        [-2.2700051e-05, -9.1859702e-06]],\n",
       "\n",
       "       [[-7.3730830e-06, -2.9384394e-06],\n",
       "        [-5.8207235e-07, -2.2942763e-07],\n",
       "        [-9.0028486e-08, -3.5189608e-08]],\n",
       "\n",
       "       [[-2.7414071e-08, -1.0645354e-08],\n",
       "        [-2.0611615e-09, -7.9617191e-10],\n",
       "        [-3.0684266e-10, -1.1801207e-10]]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dummy_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=\n",
       "array([-5.0090764e-02, -2.3471732e-03, -1.1248240e-05, -4.1341615e-08],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reduce_sum(tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), mean_dummy_grads), axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 5.9974957, 15.999882 , 28.       , 40.       ], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.reduce_sum(tf.matmul(tf.transpose(pol_one_hot, [0,2,1]), log_var_dummy_grads), axis=-1), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 3), dtype=float32, numpy=\n",
       "array([[ 0.5068394,  2.5009255,  4.5001254],\n",
       "       [ 6.500017 ,  8.500002 , 10.5      ],\n",
       "       [12.5      , 14.5      , 16.5      ],\n",
       "       [18.5      , 20.5      , 22.5      ]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(obs_losses)#.eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.map_fn(lambda x: tf.gradients(x, mean_dummy_w)[0], tf.squeeze(obs_losses, axis=-1)).eval(session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.gradients(obs_losses, mean_dummy_w)[0].eval(session=sess), tf.gradients(obs_losses, log_var_dummy_w)[0].eval(session=sess)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0762be2d7dad499f78b4ccc05029bbe082222b827c654f817432570f6c80b9f2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
